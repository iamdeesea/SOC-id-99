# Face Aging with CAAE (Conditional Adversarial Autoencoder)
# Complete implementation for face aging prediction and comparison

# Cell 1: Install required packages
!pip install torch torchvision torchaudio
!pip install opencv-python-headless
!pip install pillow
!pip install matplotlib
!pip install numpy
!pip install scipy
!pip install scikit-image
!pip install kaggle
!pip install gdown

# Cell 2: Import necessary libraries
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
import os
import zipfile
import requests
from io import BytesIO
import warnings
warnings.filterwarnings('ignore')

# Check if CUDA is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

# Cell 3: Download and setup Kaggle dataset
# First, upload your kaggle.json file to access Kaggle API
from google.colab import files
import json

# Upload kaggle.json
print("Please upload your kaggle.json file:")
uploaded = files.upload()

# Setup Kaggle API
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the human faces dataset
!kaggle datasets download -d ashwingupta3012/human-faces
!unzip human-faces.zip -d ./human_faces_dataset/

# Cell 4: Clone the Face-Aging-CAAE repository
!git clone https://github.com/ZZUTK/Face-Aging-CAAE.git
!cd Face-Aging-CAAE && ls -la

# Cell 5: Define the CAAE model architecture
class Encoder(nn.Module):
    def __init__(self, z_dim=50, c_dim=6):
        super(Encoder, self).__init__()
        self.z_dim = z_dim
        self.c_dim = c_dim
        
        # Convolutional layers
        self.conv1 = nn.Conv2d(3, 32, 4, 2, 1)  # 128x128 -> 64x64
        self.conv2 = nn.Conv2d(32, 64, 4, 2, 1)  # 64x64 -> 32x32
        self.conv3 = nn.Conv2d(64, 128, 4, 2, 1)  # 32x32 -> 16x16
        self.conv4 = nn.Conv2d(128, 256, 4, 2, 1)  # 16x16 -> 8x8
        self.conv5 = nn.Conv2d(256, 512, 4, 2, 1)  # 8x8 -> 4x4
        
        # Batch normalization
        self.bn1 = nn.BatchNorm2d(32)
        self.bn2 = nn.BatchNorm2d(64)
        self.bn3 = nn.BatchNorm2d(128)
        self.bn4 = nn.BatchNorm2d(256)
        self.bn5 = nn.BatchNorm2d(512)
        
        # Fully connected layers
        self.fc_z = nn.Linear(512 * 4 * 4, z_dim)
        self.fc_c = nn.Linear(512 * 4 * 4, c_dim)
        
    def forward(self, x):
        x = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)
        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)
        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)
        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)
        x = F.leaky_relu(self.bn5(self.conv5(x)), 0.2)
        
        x = x.view(x.size(0), -1)
        z = self.fc_z(x)
        c = self.fc_c(x)
        
        return z, c

class Decoder(nn.Module):
    def __init__(self, z_dim=50, c_dim=6):
        super(Decoder, self).__init__()
        self.z_dim = z_dim
        self.c_dim = c_dim
        
        # Fully connected layer
        self.fc = nn.Linear(z_dim + c_dim, 512 * 4 * 4)
        
        # Transposed convolutional layers
        self.deconv1 = nn.ConvTranspose2d(512, 256, 4, 2, 1)  # 4x4 -> 8x8
        self.deconv2 = nn.ConvTranspose2d(256, 128, 4, 2, 1)  # 8x8 -> 16x16
        self.deconv3 = nn.ConvTranspose2d(128, 64, 4, 2, 1)   # 16x16 -> 32x32
        self.deconv4 = nn.ConvTranspose2d(64, 32, 4, 2, 1)    # 32x32 -> 64x64
        self.deconv5 = nn.ConvTranspose2d(32, 3, 4, 2, 1)     # 64x64 -> 128x128
        
        # Batch normalization
        self.bn1 = nn.BatchNorm2d(256)
        self.bn2 = nn.BatchNorm2d(128)
        self.bn3 = nn.BatchNorm2d(64)
        self.bn4 = nn.BatchNorm2d(32)
        
    def forward(self, z, c):
        x = torch.cat([z, c], dim=1)
        x = self.fc(x)
        x = x.view(x.size(0), 512, 4, 4)
        
        x = F.relu(self.bn1(self.deconv1(x)))
        x = F.relu(self.bn2(self.deconv2(x)))
        x = F.relu(self.bn3(self.deconv3(x)))
        x = F.relu(self.bn4(self.deconv4(x)))
        x = torch.tanh(self.deconv5(x))
        
        return x

class CAAE(nn.Module):
    def __init__(self, z_dim=50, c_dim=6):
        super(CAAE, self).__init__()
        self.encoder = Encoder(z_dim, c_dim)
        self.decoder = Decoder(z_dim, c_dim)
        
    def forward(self, x, target_age=None):
        z, c = self.encoder(x)
        
        if target_age is not None:
            # Use target age for conditioning
            reconstructed = self.decoder(z, target_age)
        else:
            # Use original age conditioning
            reconstructed = self.decoder(z, c)
            
        return reconstructed, z, c

# Cell 6: Image preprocessing pipeline
class ImagePreprocessor:
    def __init__(self, target_size=(128, 128)):
        self.target_size = target_size
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        # Define transforms
        self.transform = transforms.Compose([
            transforms.Resize(target_size),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
        ])
        
    def detect_face(self, image):
        """Detect and crop face from image"""
        if isinstance(image, str):
            img = cv2.imread(image)
        else:
            img = np.array(image)
            
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)
        
        if len(faces) > 0:
            # Get the largest face
            x, y, w, h = max(faces, key=lambda face: face[2] * face[3])
            
            # Add padding
            padding = int(0.2 * max(w, h))
            x = max(0, x - padding)
            y = max(0, y - padding)
            w = min(img.shape[1] - x, w + 2 * padding)
            h = min(img.shape[0] - y, h + 2 * padding)
            
            face = img[y:y+h, x:x+w]
            return cv2.cvtColor(face, cv2.COLOR_BGR2RGB)
        else:
            # If no face detected, return original image
            return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    
    def preprocess_image(self, image_path_or_array):
        """Complete preprocessing pipeline"""
        # Detect and crop face
        face = self.detect_face(image_path_or_array)
        
        # Convert to PIL Image
        pil_image = Image.fromarray(face)
        
        # Apply transforms
        tensor_image = self.transform(pil_image)
        
        return tensor_image, pil_image

# Cell 7: Custom dataset class for face aging
class FaceAgingDataset(Dataset):
    def __init__(self, data_dir, preprocessor, age_groups=6):
        self.data_dir = data_dir
        self.preprocessor = preprocessor
        self.age_groups = age_groups
        self.image_files = []
        
        # Collect all image files
        for root, dirs, files in os.walk(data_dir):
            for file in files:
                if file.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.image_files.append(os.path.join(root, file))
        
        print(f"Found {len(self.image_files)} images")
        
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        image_path = self.image_files[idx]
        
        try:
            # Preprocess image
            tensor_image, _ = self.preprocessor.preprocess_image(image_path)
            
            # Generate random age label (for demonstration)
            age_label = torch.zeros(self.age_groups)
            age_idx = np.random.randint(0, self.age_groups)
            age_label[age_idx] = 1.0
            
            return tensor_image, age_label
        except Exception as e:
            print(f"Error processing {image_path}: {e}")
            # Return a dummy tensor if processing fails
            return torch.zeros(3, 128, 128), torch.zeros(self.age_groups)

# Cell 8: Training utilities
class FaceAgingTrainer:
    def __init__(self, model, device):
        self.model = model.to(device)
        self.device = device
        
        # Optimizers
        self.optimizer_E = torch.optim.Adam(model.encoder.parameters(), lr=0.0002, betas=(0.5, 0.999))
        self.optimizer_D = torch.optim.Adam(model.decoder.parameters(), lr=0.0002, betas=(0.5, 0.999))
        
        # Loss functions
        self.reconstruction_loss = nn.MSELoss()
        self.age_loss = nn.CrossEntropyLoss()
        
    def train_step(self, real_images, age_labels):
        batch_size = real_images.size(0)
        real_images = real_images.to(self.device)
        age_labels = age_labels.to(self.device)
        
        # Forward pass
        reconstructed, z, c = self.model(real_images)
        
        # Reconstruction loss
        recon_loss = self.reconstruction_loss(reconstructed, real_images)
        
        # Age classification loss
        age_loss = self.age_loss(c, torch.argmax(age_labels, dim=1))
        
        # Total loss
        total_loss = recon_loss + 0.1 * age_loss
        
        # Backward pass
        self.optimizer_E.zero_grad()
        self.optimizer_D.zero_grad()
        total_loss.backward()
        self.optimizer_E.step()
        self.optimizer_D.step()
        
        return {
            'total_loss': total_loss.item(),
            'recon_loss': recon_loss.item(),
            'age_loss': age_loss.item()
        }

# Cell 9: Inference pipeline
class FaceAgingInference:
    def __init__(self, model_path=None):
        self.model = CAAE()
        self.preprocessor = ImagePreprocessor()
        self.device = device
        
        if model_path and os.path.exists(model_path):
            self.model.load_state_dict(torch.load(model_path, map_location=device))
            print(f"Loaded model from {model_path}")
        else:
            print("No pre-trained model found. Using randomly initialized weights.")
            
        self.model.to(device)
        self.model.eval()
        
        # Age group definitions
        self.age_groups = ['0-10', '11-20', '21-30', '31-40', '41-50', '51+']
        
    def create_age_condition(self, target_age_group):
        """Create one-hot encoded age condition"""
        age_condition = torch.zeros(1, 6).to(self.device)
        age_condition[0, target_age_group] = 1.0
        return age_condition
    
    def age_face(self, image_input, target_age_groups=None):
        """Apply aging to a face image"""
        if target_age_groups is None:
            target_age_groups = list(range(6))
            
        # Preprocess image
        if isinstance(image_input, str):
            tensor_image, original_pil = self.preprocessor.preprocess_image(image_input)
        else:
            tensor_image, original_pil = self.preprocessor.preprocess_image(image_input)
            
        tensor_image = tensor_image.unsqueeze(0).to(self.device)
        
        results = {'original': original_pil}
        
        with torch.no_grad():
            # Get latent representation
            z, original_c = self.model.encoder(tensor_image)
            
            # Generate aged versions
            for age_idx in target_age_groups:
                target_age = self.create_age_condition(age_idx)
                aged_image = self.model.decoder(z, target_age)
                
                # Convert back to PIL image
                aged_image = aged_image.squeeze(0).cpu()
                aged_image = (aged_image + 1) / 2  # Denormalize
                aged_image = torch.clamp(aged_image, 0, 1)
                aged_image = transforms.ToPILImage()(aged_image)
                
                results[f'age_{self.age_groups[age_idx]}'] = aged_image
                
        return results

# Cell 10: Visualization utilities
def plot_aging_results(results, figsize=(15, 3)):
    """Plot original and aged face images"""
    n_images = len(results)
    fig, axes = plt.subplots(1, n_images, figsize=figsize)
    
    if n_images == 1:
        axes = [axes]
    
    for idx, (age_label, image) in enumerate(results.items()):
        axes[idx].imshow(image)
        axes[idx].set_title(age_label, fontsize=12)
        axes[idx].axis('off')
    
    plt.tight_layout()
    plt.show()

def compare_different_ages(inference_model, image_input, ages_to_compare=[0, 2, 4, 5]):
    """Compare aging results for different target ages"""
    results = inference_model.age_face(image_input, ages_to_compare)
    
    # Create comparison plot
    n_cols = len(results)
    fig, axes = plt.subplots(2, n_cols, figsize=(4*n_cols, 8))
    
    # Plot results
    for idx, (age_label, image) in enumerate(results.items()):
        if n_cols == 1:
            ax = axes[idx] if len(axes.shape) == 1 else axes[0]
        else:
            ax = axes[0, idx]
        ax.imshow(image)
        ax.set_title(f'{age_label}', fontsize=12)
        ax.axis('off')
    
    # Hide second row if not needed
    if len(axes.shape) == 2:
        for idx in range(n_cols):
            axes[1, idx].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    return results

# Cell 11: Test different lighting conditions
def test_lighting_conditions(inference_model, image_input):
    """Test model performance under different lighting conditions"""
    
    def adjust_brightness(image, factor):
        """Adjust image brightness"""
        if isinstance(image, str):
            img = cv2.imread(image)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        else:
            img = np.array(image)
        
        # Convert to float
        img_float = img.astype(np.float32) / 255.0
        
        # Adjust brightness
        img_bright = np.clip(img_float * factor, 0, 1)
        
        # Convert back to uint8
        img_bright = (img_bright * 255).astype(np.uint8)
        
        return Image.fromarray(img_bright)
    
    # Test different brightness levels
    brightness_levels = [0.5, 0.8, 1.0, 1.2, 1.5]
    lighting_results = {}
    
    for brightness in brightness_levels:
        adjusted_image = adjust_brightness(image_input, brightness)
        aged_results = inference_model.age_face(adjusted_image, [0, 2, 4])
        lighting_results[f'brightness_{brightness}'] = aged_results
    
    # Plot results
    fig, axes = plt.subplots(len(brightness_levels), 4, figsize=(16, 4*len(brightness_levels)))
    
    for row, (brightness_label, results) in enumerate(lighting_results.items()):
        for col, (age_label, image) in enumerate(results.items()):
            if col < 4:  # Limit to 4 columns
                axes[row, col].imshow(image)
                axes[row, col].set_title(f'{brightness_label}\n{age_label}', fontsize=10)
                axes[row, col].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    return lighting_results

# Cell 12: Model architecture modifications
def create_modified_caae(dropout_rate=0.2, use_spectral_norm=False):
    """Create CAAE with modifications like dropout and different normalization"""
    
    class ModifiedEncoder(nn.Module):
        def __init__(self, z_dim=50, c_dim=6, dropout_rate=0.2):
            super(ModifiedEncoder, self).__init__()
            self.dropout_rate = dropout_rate
            
            # Convolutional layers
            self.conv1 = nn.Conv2d(3, 32, 4, 2, 1)
            self.conv2 = nn.Conv2d(32, 64, 4, 2, 1)
            self.conv3 = nn.Conv2d(64, 128, 4, 2, 1)
            self.conv4 = nn.Conv2d(128, 256, 4, 2, 1)
            self.conv5 = nn.Conv2d(256, 512, 4, 2, 1)
            
            # Normalization layers
            if use_spectral_norm:
                from torch.nn.utils import spectral_norm
                self.conv1 = spectral_norm(self.conv1)
                self.conv2 = spectral_norm(self.conv2)
                self.conv3 = spectral_norm(self.conv3)
                self.conv4 = spectral_norm(self.conv4)
                self.conv5 = spectral_norm(self.conv5)
            
            self.bn1 = nn.BatchNorm2d(32)
            self.bn2 = nn.BatchNorm2d(64)
            self.bn3 = nn.BatchNorm2d(128)
            self.bn4 = nn.BatchNorm2d(256)
            self.bn5 = nn.BatchNorm2d(512)
            
            # Dropout
            self.dropout = nn.Dropout(dropout_rate)
            
            # Fully connected layers
            self.fc_z = nn.Linear(512 * 4 * 4, z_dim)
            self.fc_c = nn.Linear(512 * 4 * 4, c_dim)
            
        def forward(self, x):
            x = F.leaky_relu(self.bn1(self.conv1(x)), 0.2)
            x = self.dropout(x)
            x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2)
            x = self.dropout(x)
            x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2)
            x = self.dropout(x)
            x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2)
            x = self.dropout(x)
            x = F.leaky_relu(self.bn5(self.conv5(x)), 0.2)
            
            x = x.view(x.size(0), -1)
            x = self.dropout(x)
            
            z = self.fc_z(x)
            c = self.fc_c(x)
            
            return z, c
    
    class ModifiedCAAE(nn.Module):
        def __init__(self, z_dim=50, c_dim=6, dropout_rate=0.2):
            super(ModifiedCAAE, self).__init__()
            self.encoder = ModifiedEncoder(z_dim, c_dim, dropout_rate)
            self.decoder = Decoder(z_dim, c_dim)  # Use original decoder
            
        def forward(self, x, target_age=None):
            z, c = self.encoder(x)
            
            if target_age is not None:
                reconstructed = self.decoder(z, target_age)
            else:
                reconstructed = self.decoder(z, c)
                
            return reconstructed, z, c
    
    return ModifiedCAAE(dropout_rate=dropout_rate)

# Cell 13: Main execution and testing
def main_pipeline():
    """Main pipeline for face aging project"""
    
    print("=== Face Aging with CAAE - Complete Pipeline ===\n")
    
    # Initialize components
    print("1. Initializing model and preprocessor...")
    model = CAAE()
    preprocessor = ImagePreprocessor()
    inference_model = FaceAgingInference()
    
    # Setup dataset (if available)
    if os.path.exists('./human_faces_dataset/'):
        print("2. Setting up dataset...")
        dataset = FaceAgingDataset('./human_faces_dataset/', preprocessor)
        dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)
        print(f"Dataset loaded with {len(dataset)} images")
    else:
        print("2. Dataset not found. Skipping dataset setup.")
        dataloader = None
    
    # Training (simplified version for demonstration)
    if dataloader is not None:
        print("3. Training model (simplified demo)...")
        trainer = FaceAgingTrainer(model, device)
        
        # Train for a few iterations
        model.train()
        for i, (images, age_labels) in enumerate(dataloader):
            if i >= 5:  # Just a few iterations for demo
                break
            losses = trainer.train_step(images, age_labels)
            print(f"Iteration {i+1}: Loss = {losses['total_loss']:.4f}")
    
    print("4. Testing inference pipeline...")
    
    # Test with a sample image (you can upload your own)
    print("Please upload a face image to test:")
    uploaded_files = files.upload()
    
    if uploaded_files:
        image_path = list(uploaded_files.keys())[0]
        print(f"Testing with uploaded image: {image_path}")
        
        # Test basic aging
        print("5. Testing basic age transformation...")
        aging_results = inference_model.age_face(image_path)
        plot_aging_results(aging_results)
        
        # Test age comparisons
        print("6. Testing age comparisons...")
        comparison_results = compare_different_ages(inference_model, image_path)
        
        # Test lighting conditions
        print("7. Testing different lighting conditions...")
        lighting_results = test_lighting_conditions(inference_model, image_path)
        
        # Test modified model
        print("8. Testing modified model with dropout...")
        modified_model = create_modified_caae(dropout_rate=0.3)
        modified_inference = FaceAgingInference()
        modified_inference.model = modified_model
        
        modified_results = modified_inference.age_face(image_path, [0, 2, 4])
        plot_aging_results(modified_results)
        
        print("Pipeline completed successfully!")
        
    else:
        print("No image uploaded. Using random test data.")
        # Create dummy test
        dummy_image = torch.randn(1, 3, 128, 128)
        print("Created dummy test data.")

# Cell 14: Save and load model utilities
def save_model(model, path):
    """Save model checkpoint"""
    torch.save({
        'model_state_dict': model.state_dict(),
        'model_config': {
            'z_dim': 50,
            'c_dim': 6
        }
    }, path)
    print(f"Model saved to {path}")

def load_model(path):
    """Load model checkpoint"""
    checkpoint = torch.load(path, map_location=device)
    model = CAAE()
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    print(f"Model loaded from {path}")
    return model

# Cell 15: Evaluation metrics
def calculate_aging_metrics(original_image, aged_image):
    """Calculate metrics for aging quality"""
    
    # Convert to numpy arrays
    if isinstance(original_image, Image.Image):
        orig_array = np.array(original_image)
    else:
        orig_array = original_image
        
    if isinstance(aged_image, Image.Image):
        aged_array = np.array(aged_image)
    else:
        aged_array = aged_image
    
    # Calculate SSIM (Structural Similarity Index)
    from skimage.metrics import structural_similarity as ssim
    
    # Convert to grayscale for SSIM calculation
    orig_gray = cv2.cvtColor(orig_array, cv2.COLOR_RGB2GRAY)
    aged_gray = cv2.cvtColor(aged_array, cv2.COLOR_RGB2GRAY)
    
    ssim_score = ssim(orig_gray, aged_gray)
    
    # Calculate MSE
    mse = np.mean((orig_array.astype(float) - aged_array.astype(float)) ** 2)
    
    # Calculate PSNR
    if mse == 0:
        psnr = float('inf')
    else:
        psnr = 20 * np.log10(255.0 / np.sqrt(mse))
    
    return {
        'ssim': ssim_score,
        'mse': mse,
        'psnr': psnr
    }

# Cell 16: Run the complete pipeline
if __name__ == "__main__":
    main_pipeline()

# Cell 17: Additional testing functions
def batch_process_images(inference_model, image_dir, output_dir):
    """Process multiple images in batch"""
    os.makedirs(output_dir, exist_ok=True)
    
    image_files = [f for f in os.listdir(image_dir) 
                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    
    for image_file in image_files:
        image_path = os.path.join(image_dir, image_file)
        results = inference_model.age_face(image_path)
        
        # Save results
        base_name = os.path.splitext(image_file)[0]
        for age_label, aged_image in results.items():
            output_path = os.path.join(output_dir, f"{base_name}_{age_label}.jpg")
            aged_image.save(output_path)
        
        print(f"Processed {image_file}")

# Cell 18: Create comparison grid
def create_comparison_grid(results_dict, save_path=None):
    """Create a grid comparing different aging results"""
    n_images = len(results_dict)
    age_groups = list(next(iter(results_dict.values())).keys())
    n_ages = len(age_groups)
    
    fig, axes = plt.subplots(n_images, n_ages, figsize=(3*n_ages, 3*n_images))
    
    if n_images == 1:
        axes = axes.reshape(1, -1)
    
    for row, (img_name, results) in enumerate(results_dict.items()):
        for col, (age_label, image) in enumerate(results.items()):
            axes[row, col].imshow(image)
            if row == 0:
                axes[row, col].set_title(age_label, fontsize=12)
            if col == 0:
                axes[row, col].set_ylabel(img_name, rotation=90, fontsize=12)
            axes[row, col].axis('off')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Comparison grid saved to {save_path}")
    
    plt.show()

print("Face Aging CAAE Notebook Setup Complete!")
print("Run the cells in order to execute the complete pipeline.")
print("\nKey Features:")
print("- Complete CAAE implementation")
print("- Image preprocessing with face detection")
print("- Training pipeline")
print("- Inference and aging prediction")
print("- Comparison tools
