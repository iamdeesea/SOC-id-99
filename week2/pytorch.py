# -*- coding: utf-8 -*-
"""simple_NeuralNetwork.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d56IIMn3ucJIziee4s5uORV90RDFezZI
"""

import torch
import torch.nn as nn
import torch.nn.functional as F

#create a model class for nn module
class Model(nn.Module):
  def __init__(self,in_features=4,h1=8,h2=9,out_features=3):
    super().__init__() #initiate nn.module
    self.fc1=nn.Linear(in_features,h1)
    self.fc2=nn.Linear(h1,h2)
    self.out = nn.Linear(h2,out_features)

  def forward(self,x):
    x=F.relu(self.fc1(x))
    x=F.relu(self.fc2(x))
    x=self.out(x)

    return x

#pick a manual seed for randomisation
torch.manual_seed(41)
#create an instance of model
model = Model()

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline

url='https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'
my_df=pd.read_csv(url)

my_df

#changing last columns
my_df['species'] = my_df['species'].replace('setosa',0.0)
my_df['species'] = my_df['species'].replace('versicolor',1.0)
my_df['species'] = my_df['species'].replace('virginica',2.0)

my_df

#train test split
X=my_df.drop('species',axis=1)
Y=my_df['species']

"""#convert these to numpy arrays

"""

X=X.values
Y=Y.values

from sklearn.model_selection import train_test_split

#train test split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=41)

#convert x features to float tensors
X_train=torch.FloatTensor(X_train)
X_test = torch.FloatTensor(X_test)

y_train = torch.tensor(y_train.to_numpy(), dtype=torch.long)
y_test = torch.tensor(y_test.to_numpy(), dtype=torch.long)

#setting criterion for measuring the error
criterion = nn.CrossEntropyLoss()
#choose Optimizer
optimizer= torch.optim.Adam(model.parameters(),lr=0.01)

model.parameters

#train our model
#epochs-runthru one time thru all data
epochs=100
losses = []
for i in range(epochs):
  #go forward and get a prediction
  y_pred =model.forward(X_train)#get predicted results

  #measure the loss/error
  loss=criterion(y_pred,y_train)
  #keep track of losses
  losses.append(loss.detach().numpy())
  #print every 10 epoch
  if i %10 ==0:
    print(f'Epoch: {i} and loss: {loss}')
    #do some back propogation
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

